<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Machine Learning on AndreLimZS</title>
    <link>https://andrelimzs.github.io/posts/machine-learning/</link>
    <description>Recent content in Machine Learning on AndreLimZS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://andrelimzs.github.io/posts/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Unsupervised Learning</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/unsupervised-learning/</link>
      <pubDate>Sat, 25 Jun 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/unsupervised-learning/</guid>
      <description>Clustering &amp;amp; K-Means Expectation Maximization (EM) Algorithms Principal Component Analysis (PCA) Independent Component Analysis (ICA) Self-Supervised Learning </description>
    </item>
    
    <item>
      <title>Regularization and Model Selection</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/regularization/</link>
      <pubDate>Fri, 24 Jun 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/regularization/</guid>
      <description>Regularization There is a tradeoff between bias (underfitting) and variance (overfitting). The optimal tradeoff requires computing the correct model complexity.
Model Complexity : Can be a function of the parameters ($l_2$ norm) and not just the number of parameters
Regularization : Allows us to:
Control model complexity Prevent overfitting Regularizer Function A regularizer $R(\theta)$, is a function which measures model complexity. It is usually nonnegative.
In classical methods : $R(\theta)$ depends only on parameters $\theta$</description>
    </item>
    
    <item>
      <title>Generalization</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/generalisation/</link>
      <pubDate>Thu, 23 Jun 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/generalisation/</guid>
      <description>Generalisation The ultimate goal of machine learning is to create a predictive model which performs well on unseen examples (it generalises well).
Generalization is a model&amp;rsquo;s performance on unseen test data, measured by test error (loss on unseen test data).
Test Error Loss/error on test examples $(x,y)$ sampled from a test distribution $\mathcal{D}$ $$ L(\theta) = \mathbb{E}_{(x,y)\sim\mathcal{D}} [ (y-h_\theta(x))^2] $$ The expectation $\mathbb E$ can be approximated by averaging many samples</description>
    </item>
    
    <item>
      <title>Reinforcement Learning</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/reinforcement-learning/</link>
      <pubDate>Mon, 11 Apr 2022 23:59:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/reinforcement-learning/</guid>
      <description>Reinforcement Learning Many sequential decision making and control problems are hard to provide explicit supervision for.
Instead provide a reward function and let the learning algorithm figure out how to choose actions over time.
Successful in applications such as helicopter flight, legged locomotion, network routing, marketing strategy selection, etc
Markov Decision Processes (MDP) Provide formalism for many RL problems
Terminology States : $s$ Actions : $a$ State Transition Probabilities : $P_{sa}$ Discount Factor : $\gamma \in [0,1)$ Reward Function : $R : S \times A \mapsto \mathbb{R}$ Dynamics of MDPs Start in some state $s_0$ Choose some action $a_0 \in A$ MDP randomly transitions to successor state $s_1 \sim P_{s_0a_0}$ Pick another action Repeat Represent as $$ s_0 \overset{a_0}{\rightarrow} s_1 \overset{a_1}{\rightarrow} s_2 \overset{a_2}{\rightarrow} s_3 \overset{a_3}{\rightarrow} \dots $$ Total Payoff $$ R(s_0, a_0) + \gamma R(s_1, a_1) + \gamma^2 R(s_2, a_2) + \dots $$ Goal : Maximise expected value of total payoff $$ E \left[ R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \dots \right] $$</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/deep-learning/</link>
      <pubDate>Sun, 10 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/deep-learning/</guid>
      <description>Deep Learning Supervised with Nonlinear Models Supervised learning is
Predict $y$ from input $x$ Suppose model/hypothesis is $h_\theta(x)$ Previous methods have considered
Linear regression : $h_\theta(x) = \theta^Tx$ Kernel method : $h_\theta(x) = \theta^T \phi(x)$ Both are linear in $\theta$
Now consider models that are nonlinear in both
Parameters : $\theta$ Inputs : $x$ The most common of which is the neural network
Cost/Loss Function Define least-squares cost for one sample $$ J^{(i)}(\theta) = \frac{1}{2} ( h_\theta(x^{(i)}) - y^{(i)})^2 $$ and mean-square cost for the dataset $$ J(\theta) = \frac{1}{n} \sum_{i=1}^{n} J^{(i)}(\theta) $$</description>
    </item>
    
    <item>
      <title>Support Vector Machine (SVM)</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/support-vector-machines/</link>
      <pubDate>Sat, 09 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/support-vector-machines/</guid>
      <description>Support Vector Machines For the linear classifier $$ h_{w,b}(x) = g(w^T x + b) $$ with $y \in {-1, 1}$
Margins Margins represent the idea of how confident and correct a prediction is.
Functional Margin, $\hat \gamma$ The functional margin is defined as $$ \hat{\gamma}^{(i)} = y^{(i)} (w^T x^{(i)} + b) $$
And it requires some sort of normalization condition.
Otherwise the functional margin can be made arbitrarily large by scaling $w$ and $b$ without changing the decision boundary.</description>
    </item>
    
    <item>
      <title>Kernel Methods</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/kernel-methods/</link>
      <pubDate>Fri, 08 Apr 2022 22:30:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/kernel-methods/</guid>
      <description>Kernel Methods What if $y$ can be more accurately represented as a nonlinear function of $x$?
Regression can be performed on a nonlinear basis
The original input attributes are mapped to new feature variables via a feature map, $\phi$
LMS with Features Modify gradient descent for ordinary least squares problem $$ \theta := \theta + \alpha \sum_{i=1}^{n}{(y^{(i)} - \theta^T x^{(i)})\ x^{(i)}} $$ With a feature map $\phi : \mathbb R^d \rightarrow \mathbb R^p$ that maps $x$ to $\phi(x)$ $$ \theta := \theta + \alpha \sum_{i=1}^{n}{(y^{(i)} - \theta^T \phi(x^{(i)}))\ \phi(x^{(i)}}) $$ and (SGD update rule) $$ \theta := \theta + \alpha (y^{(i)} - \theta^T \phi(x^{(i)}))\ \phi(x^{(i)}) $$</description>
    </item>
    
    <item>
      <title>Generative Learning</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/generative-learning/</link>
      <pubDate>Thu, 07 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/generative-learning/</guid>
      <description>Generative Learning Different approach to learning
Try to model $p(x|y)$ and $p(y)$ instead of learning $p(y|x)$ directly
$p(x|y)$ : Distribution of the target&amp;rsquo;s features $p(y)$ : Class priors Use Bayes rule to calculate posterior distribution $p(y|x)$ $$ p(y|x) = \frac{p(x|y) p(y)}{p(x)} $$ Can be simplified when using for prediction because denominator doesn&amp;rsquo;t matter $$ \arg \max_y P(y|x) = \arg \max_y p(x|y) p(y) $$
Multivariate Normal Distribution In $d$-dimensions Parameterised by:</description>
    </item>
    
    <item>
      <title>Generalised Linear Models (GLM)</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/generalised-linear-models/</link>
      <pubDate>Wed, 06 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/generalised-linear-models/</guid>
      <description>Generalised Linear Models (GLM) Generalised Linear Models (GLMs) are a family of models which include many common distributions such as Gaussian, Bernoulli and Multinomial.
The Exponential Family The exponential family serves as a starting point for GLMs.
The exponential family is defined as $$ p(y; \eta) = b(y) \ \exp{\left( \eta^T\ T(y) - a(\eta) \right)} $$
Natural (Canonical) parameter : $\eta$ Sufficient statistic : $T(y)$ Log Partition function : $a(\eta)$ $T(y)$ is often chosen to be $T(y) = y$</description>
    </item>
    
    <item>
      <title>Supervised Learning - Classification</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/supervised-learning-classification/</link>
      <pubDate>Wed, 06 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/supervised-learning-classification/</guid>
      <description>Classification Classification is similar to regression, except output $y$ only takes on a small number of discrete values, or classes.
Logistic Regression Ignoring the fact that $y$ is discrete will often result in very poor performance. $h_\theta(x)$ should also be constrained to $y \in { 0, 1 }$
One approach is to modify the hypothesis function to use the logistic / sigmoid function $$ h_\theta(x) = g(\theta^Tx) = \frac{1}{1 + e^{-\theta^Tx}} $$ where $g(z) = \frac{1}{1 + e^{-z}}$ is the logistic/sigmoid function</description>
    </item>
    
    <item>
      <title>Supervised Learning - Regression</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/supervised-learning-regression/</link>
      <pubDate>Wed, 06 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/supervised-learning-regression/</guid>
      <description>Supervised Learning Supervised learning is the task of learning a function mapping from input to output $$ y = f(x) $$ The relationship can be linear/nonlinear or convex/nonconvex. The approach learns from labeled data.
Terminology Input (Features) : $x^{(i)}$
Output (Target) : $y^{(i)}$
Training example : $(x^{(i)}, y^{(i)})$
Hypothesis : $h(x)$
Parameters / Weights : $\theta$
Types Regression : Continuous values
Classification : Discrete values
Linear Regression Objective
Learn parameters $\theta$ for a given hypthesis function $h$ to best predict output $y$ from input $x$</description>
    </item>
    
    <item>
      <title>Probability Theory</title>
      <link>https://andrelimzs.github.io/posts/machine-learning/cs229-0-probability-theory/</link>
      <pubDate>Tue, 05 Apr 2022 22:00:00 +0800</pubDate>
      
      <guid>https://andrelimzs.github.io/posts/machine-learning/cs229-0-probability-theory/</guid>
      <description>Review of Probability Theory Overview Probability is an important aspect of machine learning, and forms a useful basis for concepts. It is the study of uncertainty
Elements of Probability Defining probability on a set requires the following:
Sample Space : $\Omega$
The set of all possible outcomes of a random experiment Each outcome $\omega \in \Omega$ is the complete description of the state at the end of the experiment Event Space (Set of events) : $\mathcal{F}$</description>
    </item>
    
  </channel>
</rss>
