<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Machine Learning | AndreLimZS</title><meta name=keywords content><meta name=description content="Machine Learning - AndreLimZS"><meta name=author content="Andre Lim"><link rel=canonical href=https://andrelimzs.github.io/posts/machine-learning/><link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style><link rel=icon href=https://andrelimzs.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://andrelimzs.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://andrelimzs.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://andrelimzs.github.io/apple-touch-icon.png><link rel=mask-icon href=https://andrelimzs.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.101.0"><link rel=alternate type=application/rss+xml href=https://andrelimzs.github.io/posts/machine-learning/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Machine Learning"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://andrelimzs.github.io/posts/machine-learning/"><meta property="og:site_name" content="AndreLimZS"><meta name=twitter:card content="summary"><meta name=twitter:title content="Machine Learning"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://andrelimzs.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Machine Learning","item":"https://andrelimzs.github.io/posts/machine-learning/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://andrelimzs.github.io accesskey=h title="AndreLimZS (Alt + H)">AndreLimZS</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://andrelimzs.github.io/posts/machine-learning/ title="Machine Learning"><span class=active>Machine Learning</span></a></li><li><a href=https://andrelimzs.github.io/posts/cnc-mill/ title="CNC Mill"><span>CNC Mill</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://andrelimzs.github.io>Home</a>&nbsp;»&nbsp;<a href=https://andrelimzs.github.io/posts/>Posts</a></div><h1>Machine Learning</h1></header><article class=post-entry><header class=entry-header><h2>Unsupervised Learning</h2></header><section class=entry-content><p>Clustering & K-Means Expectation Maximization (EM) Algorithms Principal Component Analysis (PCA) Independent Component Analysis (ICA) Self-Supervised Learning</p></section><footer class=entry-footer><span title='2022-06-25 22:00:00 +0800 +0800'>June 25, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Unsupervised Learning" href=https://andrelimzs.github.io/posts/machine-learning/unsupervised-learning/></a></article><article class=post-entry><header class=entry-header><h2>Regularization and Model Selection</h2></header><section class=entry-content><p>Regularization There is a tradeoff between bias (underfitting) and variance (overfitting). The optimal tradeoff requires computing the correct model complexity.
Model Complexity : Can be a function of the parameters ($l_2$ norm) and not just the number of parameters
Regularization : Allows us to:
Control model complexity Prevent overfitting Regularizer Function A regularizer $R(\theta)$, is a function which measures model complexity. It is usually nonnegative.
In classical methods : $R(\theta)$ depends only on parameters $\theta$...</p></section><footer class=entry-footer><span title='2022-06-24 22:00:00 +0800 +0800'>June 24, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Regularization and Model Selection" href=https://andrelimzs.github.io/posts/machine-learning/regularization/></a></article><article class=post-entry><header class=entry-header><h2>Generalization</h2></header><section class=entry-content><p>Generalisation The ultimate goal of machine learning is to create a predictive model which performs well on unseen examples (it generalises well).
Generalization is a model’s performance on unseen test data, measured by test error (loss on unseen test data).
Test Error Loss/error on test examples $(x,y)$ sampled from a test distribution $\mathcal{D}$ $$ L(\theta) = \mathbb{E}_{(x,y)\sim\mathcal{D}} [ (y-h_\theta(x))^2] $$ The expectation $\mathbb E$ can be approximated by averaging many samples...</p></section><footer class=entry-footer><span title='2022-06-23 22:00:00 +0800 +0800'>June 23, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Generalization" href=https://andrelimzs.github.io/posts/machine-learning/generalisation/></a></article><article class=post-entry><header class=entry-header><h2>Reinforcement Learning</h2></header><section class=entry-content><p>Reinforcement Learning Many sequential decision making and control problems are hard to provide explicit supervision for.
Instead provide a reward function and let the learning algorithm figure out how to choose actions over time.
Successful in applications such as helicopter flight, legged locomotion, network routing, marketing strategy selection, etc
Markov Decision Processes (MDP) Provide formalism for many RL problems
Terminology States : $s$ Actions : $a$ State Transition Probabilities : $P_{sa}$ Discount Factor : $\gamma \in [0,1)$ Reward Function : $R : S \times A \mapsto \mathbb{R}$ Dynamics of MDPs Start in some state $s_0$ Choose some action $a_0 \in A$ MDP randomly transitions to successor state $s_1 \sim P_{s_0a_0}$ Pick another action Repeat Represent as $$ s_0 \overset{a_0}{\rightarrow} s_1 \overset{a_1}{\rightarrow} s_2 \overset{a_2}{\rightarrow} s_3 \overset{a_3}{\rightarrow} \dots $$ Total Payoff $$ R(s_0, a_0) + \gamma R(s_1, a_1) + \gamma^2 R(s_2, a_2) + \dots $$ Goal : Maximise expected value of total payoff $$ E \left[ R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \dots \right] $$...</p></section><footer class=entry-footer><span title='2022-04-11 23:59:00 +0800 +0800'>April 11, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Reinforcement Learning" href=https://andrelimzs.github.io/posts/machine-learning/reinforcement-learning/></a></article><article class=post-entry><header class=entry-header><h2>Deep Learning</h2></header><section class=entry-content><p>Deep Learning Supervised with Nonlinear Models Supervised learning is
Predict $y$ from input $x$ Suppose model/hypothesis is $h_\theta(x)$ Previous methods have considered
Linear regression : $h_\theta(x) = \theta^Tx$ Kernel method : $h_\theta(x) = \theta^T \phi(x)$ Both are linear in $\theta$
Now consider models that are nonlinear in both
Parameters : $\theta$ Inputs : $x$ The most common of which is the neural network
Cost/Loss Function Define least-squares cost for one sample $$ J^{(i)}(\theta) = \frac{1}{2} ( h_\theta(x^{(i)}) - y^{(i)})^2 $$ and mean-square cost for the dataset $$ J(\theta) = \frac{1}{n} \sum_{i=1}^{n} J^{(i)}(\theta) $$...</p></section><footer class=entry-footer><span title='2022-04-10 22:00:00 +0800 +0800'>April 10, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Deep Learning" href=https://andrelimzs.github.io/posts/machine-learning/deep-learning/></a></article><article class=post-entry><header class=entry-header><h2>Support Vector Machine (SVM)</h2></header><section class=entry-content><p>Support Vector Machines For the linear classifier $$ h_{w,b}(x) = g(w^T x + b) $$ with $y \in {-1, 1}$
Margins Margins represent the idea of how confident and correct a prediction is.
Functional Margin, $\hat \gamma$ The functional margin is defined as $$ \hat{\gamma}^{(i)} = y^{(i)} (w^T x^{(i)} + b) $$
And it requires some sort of normalization condition.
Otherwise the functional margin can be made arbitrarily large by scaling $w$ and $b$ without changing the decision boundary....</p></section><footer class=entry-footer><span title='2022-04-09 22:00:00 +0800 +0800'>April 9, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Support Vector Machine (SVM)" href=https://andrelimzs.github.io/posts/machine-learning/support-vector-machines/></a></article><article class=post-entry><header class=entry-header><h2>Kernel Methods</h2></header><section class=entry-content><p>Kernel Methods Kernel methods are an efficient way to perform nonlinear regression or classification, by calculating the dot product instead of the entire feature map.
Feature Maps A feature map $\phi$ is a function that maps input attributes to some new (nonlinear) feature variables.
LMS with Features First lets define:
Input : $x \in \mathbb R ^ d$ Features : $\phi(x) \in \mathbb R^{p}$ Weights : $\theta \in \mathbb R^d$ Modify gradient descent for ordinary le2ast squares problem $$ \theta := \theta + \alpha \sum_{i=1}^{n}{(y^{(i)} - \theta^T x^{(i)})\ x^{(i)}} $$ With a feature map $\phi : \mathbb R^d \rightarrow \mathbb R^p$ that maps $x$ to $\phi(x)$ $$ \theta := \theta + \alpha \sum_{i=1}^{n}{(y^{(i)} - \theta^T \underbrace{\phi(x^{(i)})} )\ \underbrace{\phi(x^{(i)}})} $$ Which will have SGD update rule $$ \theta := \theta + \alpha (y^{(i)} - \theta^T \phi(x^{(i)}))\ \phi(x^{(i)}) $$...</p></section><footer class=entry-footer><span title='2022-04-08 22:30:00 +0800 +0800'>April 8, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Kernel Methods" href=https://andrelimzs.github.io/posts/machine-learning/kernel-methods/></a></article><article class=post-entry><header class=entry-header><h2>Generative Learning</h2></header><section class=entry-content><p>Generative Learning Generative learning is a different approach to learning as opposed to discriminative learning. It tries to model $p(x|y)$ and $p(y)$ instead of learning $p(y|x)$ directly.
$p(x|y)$ : Distribution of the target’s features $p(y)$ : Class priors It uses Bayes rule to calculate posterior distribution $p(y|x)$ $$ p(y|x) = \frac{p(x|y) p(y)}{p(x)} $$ And can be simplified when using for prediction because the denominator is constant and doesn’t matter $$ \arg \max_y P(y|x) = \arg \max_y p(x|y) p(y) $$...</p></section><footer class=entry-footer><span title='2022-04-07 22:00:00 +0800 +0800'>April 7, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Generative Learning" href=https://andrelimzs.github.io/posts/machine-learning/generative-learning/></a></article><article class=post-entry><header class=entry-header><h2>Generalised Linear Models (GLM)</h2></header><section class=entry-content><p>Generalised Linear Models (GLM) Generalised Linear Models (GLMs) are a family of models which include many common distributions such as Gaussian, Bernoulli and Multinomial.
The Exponential Family The exponential family serves as a starting point for GLMs.
The exponential family is defined as $$ p(y; \eta) = b(y) \ \exp{\left( \eta^T\ T(y) - a(\eta) \right)} $$
Natural (Canonical) parameter : $\eta$ Sufficient statistic : $T(y)$ Log Partition function : $a(\eta)$ $T(y)$ is often chosen to be $T(y) = y$...</p></section><footer class=entry-footer><span title='2022-04-06 22:00:00 +0800 +0800'>April 6, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Generalised Linear Models (GLM)" href=https://andrelimzs.github.io/posts/machine-learning/generalised-linear-models/></a></article><article class=post-entry><header class=entry-header><h2>Supervised Learning - Classification</h2></header><section class=entry-content><p>Classification Classification is similar to regression, except output $y$ only takes on a small number of discrete values, or classes.
Logistic Regression Ignoring the fact that $y$ is discrete will often result in very poor performance. $h_\theta(x)$ should also be constrained to $y \in { 0, 1 }$
One approach is to modify the hypothesis function to use the logistic / sigmoid function $$ h_\theta(x) = g(\theta^Tx) = \frac{1}{1 + e^{-\theta^Tx}} $$ where $g(z) = \frac{1}{1 + e^{-z}}$ is the logistic/sigmoid function...</p></section><footer class=entry-footer><span title='2022-04-06 22:00:00 +0800 +0800'>April 6, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Andre Lim</footer><a class=entry-link aria-label="post link to Supervised Learning - Classification" href=https://andrelimzs.github.io/posts/machine-learning/supervised-learning-classification/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://andrelimzs.github.io/posts/machine-learning/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://andrelimzs.github.io>AndreLimZS</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>