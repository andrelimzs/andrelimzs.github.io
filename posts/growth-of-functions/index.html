<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta name=robots content="index, follow"><title>Growth of Functions | AndreLimZS</title><meta name=keywords content><meta name=description content="Objective Order of growth is a simple characterization of an algorithm&rsquo;s efficiency and allows for comparison between algorithms.
Asymptotic Efficiency When we look at input size $n$ large enough that only the order of growth matters. We are concerned with the running time in the limit as input increases without bound.
Asymptotic Notation Notation is defined as a function on domain $\mathbb{N} = { 0,1,2,\dots }$, the set of natural numbers."><meta name=author content><link rel=canonical href=https://andrelimzs.github.io/posts/growth-of-functions/><link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://andrelimzs.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://andrelimzs.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://andrelimzs.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://andrelimzs.github.io/apple-touch-icon.png><link rel=mask-icon href=https://andrelimzs.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.94.2"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Growth of Functions"><meta property="og:description" content="Objective Order of growth is a simple characterization of an algorithm&rsquo;s efficiency and allows for comparison between algorithms.
Asymptotic Efficiency When we look at input size $n$ large enough that only the order of growth matters. We are concerned with the running time in the limit as input increases without bound.
Asymptotic Notation Notation is defined as a function on domain $\mathbb{N} = { 0,1,2,\dots }$, the set of natural numbers."><meta property="og:type" content="article"><meta property="og:url" content="https://andrelimzs.github.io/posts/growth-of-functions/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-01-17T23:05:22+08:00"><meta property="article:modified_time" content="2022-01-17T23:05:22+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Growth of Functions"><meta name=twitter:description content="Objective Order of growth is a simple characterization of an algorithm&rsquo;s efficiency and allows for comparison between algorithms.
Asymptotic Efficiency When we look at input size $n$ large enough that only the order of growth matters. We are concerned with the running time in the limit as input increases without bound.
Asymptotic Notation Notation is defined as a function on domain $\mathbb{N} = { 0,1,2,\dots }$, the set of natural numbers."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://andrelimzs.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Growth of Functions","item":"https://andrelimzs.github.io/posts/growth-of-functions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Growth of Functions","name":"Growth of Functions","description":"Objective Order of growth is a simple characterization of an algorithm\u0026rsquo;s efficiency and allows for comparison between algorithms.\nAsymptotic Efficiency When we look at input size $n$ large enough that only the order of growth matters. We are concerned with the running time in the limit as input increases without bound.\nAsymptotic Notation Notation is defined as a function on domain $\\mathbb{N} = { 0,1,2,\\dots }$, the set of natural numbers.","keywords":[],"articleBody":"Objective Order of growth is a simple characterization of an algorithmâ€™s efficiency and allows for comparison between algorithms.\nAsymptotic Efficiency When we look at input size $n$ large enough that only the order of growth matters. We are concerned with the running time in the limit as input increases without bound.\nAsymptotic Notation Notation is defined as a function on domain $\\mathbb{N} = { 0,1,2,\\dots }$, the set of natural numbers. It is mainly used to characterise running time, but can also be used on memory/space/etc.\n$\\Theta$-notation  Encloses the function from above and below\n Useful in analyzing the average-case complexity of an algorithm. $$ \\begin{aligned} \\Theta \\big( g(n) \\big) = \\{ f(n) :\\ \\text{there exists } c_1,\\ c_2,\\ n_0 \\text{ such that } \\\\ 0 \\leq c_1 g(n) \\leq f(n) \\leq c_2 g(n) \\enspace \\forall n \\geq n_0 \\} \\end{aligned} $$ $\\Theta(n)$ is a set, but it is usually written as $f(n) = \\Theta(n)$.\n $f(n)$ belongs to set $\\Theta(g(n))$ if $c_1 \\cdot g(n)$ and $c_2 \\cdot g(n)$ can sandwidch the function, for large $n \\geq n_0$.\nThe function $f(n)$ is equal to $g(n)$ to within a constant factor, which makes $g(n)$ an asymptotically tight bound for $f(n)$.\nThe definition of $\\Theta(n)$ requires all $f(n) \\in \\Theta(g(n))$ be asymptotically nonnegative ($f(n) \\geq 0$ as $n \\rightarrow \\infty$. This implies that $g(n)$ is also asymptotically nonnegative so that $\\Theta(g(n))$ is not empty. Therefore assume that every function in $\\Theta$-notation is asymptotically nonnegative.\n Example Show that $ \\frac{3}{4} n^2 - 5n + \\frac{3}{n} = \\Theta(n^2) $\n$c_1 n^2 \\leq \\frac{3}{4} n^2 - 5n + \\frac{3}{n} \\leq c_2 n^2$ for all $n \\geq n_0$\n$c_1 \\leq \\frac{3}{4} - \\frac{5}{n} + \\frac{3}{n^2} \\leq c_2$\n$c_1 = \\frac{1}{2}$, $c_2 = 1$ and $n_0 = 10$ satisfy the inequality\n  Example Show that $5n^3 \\neq \\Theta(n^2)$\n$c_1 \\leq 5 \\frac{n^3}{n^2} \\leq c_2$\nWhich cannot hold for arbitrarily large $n$\n This results in two observations:\n The lower-order terms can be ignored (They become of the form $1 / n^k$ which go to $0$) Coefficients can be ignored (Can be divided into $c_1, c_2$)  Constants are degree-0 polynomials, which can be expressed as $\\Theta(n^0)$ or more commonly $\\Theta(1)$.\n$O$-notation  Asymptotic upper bound\n Provides an upper bound on a function to within a constant factor. $$ \\begin{aligned} O \\big( g(n) \\big) = \\{ f(n) :\\ \\text{there exists } c,\\ n_0 \\text{ such that } \\\\ 0 \\leq f(n) \\leq c g(n) \\enspace \\forall n \\geq n_0 \\} \\end{aligned} $$ $\\Theta(g(n))$ implies $O(g(n))$ becauses $\\Theta$-notation is stronger than $O$-notation. $$ \\Theta(g(n)) \\subseteq O(g(n)) $$ $O$-notation provides an asymptotic upper bound but not a tight one. Distinguishing between both is stanard in algorithms literature, but not in informal use.\nInspection can often reveal the $O$-notation running time. For example, double nested loops are $O(n^2)$.\nWhen $O$-notation is used to bound the worst-case running time, it also bounds every input. This is different from $\\Theta$-notation, where the worse-case does not imply the running time for every input.\n$\\Omega$-notation  Asymptotic lower bound\n $$ \\begin{aligned} O \\big( g(n) \\big) = \\{ f(n) :\\ \\text{there exists } c,\\ n_0 \\text{ such that } \\\\ 0 \\leq c g(n) \\leq f(n) \\enspace \\forall n \\geq n_0 \\} \\end{aligned} $$\nTheorem 3.1 For any two functions $f(n)$ and $g(n)$, we have $f(n) = \\Theta(g(n))$ if and only if $f(n) = O(g(n)) and f(n) = \\Omega(g(n))$\nCommonly used to get asymptotic upper/lower bounds ( $O$ / $\\Omega$ ) from tight bounds ( $\\Theta$ )\n Example\n$ \\Omega(n^2) = an^2 + bn + c$ and $O(n^2) = an^2 + bn + c$\nimply that $ \\Theta(n^2) = an^2 + bn + c $\n ","wordCount":"602","inLanguage":"en","datePublished":"2022-01-17T23:05:22+08:00","dateModified":"2022-01-17T23:05:22+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://andrelimzs.github.io/posts/growth-of-functions/"},"publisher":{"@type":"Organization","name":"AndreLimZS","logo":{"@type":"ImageObject","url":"https://andrelimzs.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://andrelimzs.github.io accesskey=h title="AndreLimZS (Alt + H)">AndreLimZS</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Growth of Functions</h1><div class=post-meta><span title="2022-01-17 23:05:22 +0800 +0800">January 17, 2022</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#objective aria-label=Objective>Objective</a><ul><li><a href=#asymptotic-efficiency aria-label="Asymptotic Efficiency">Asymptotic Efficiency</a></li></ul></li><li><a href=#asymptotic-notation aria-label="Asymptotic Notation">Asymptotic Notation</a><ul><li><a href=#theta-notation aria-label=$\Theta$-notation>$\Theta$-notation</a></li><li><a href=#o-notation aria-label=$O$-notation>$O$-notation</a></li><li><a href=#omega-notation aria-label=$\Omega$-notation>$\Omega$-notation</a></li><li><a href=#theorem-31 aria-label="Theorem 3.1">Theorem 3.1</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=objective>Objective<a hidden class=anchor aria-hidden=true href=#objective>#</a></h2><p>Order of growth is a simple characterization of an algorithm&rsquo;s efficiency and allows for comparison between algorithms.</p><h3 id=asymptotic-efficiency>Asymptotic Efficiency<a hidden class=anchor aria-hidden=true href=#asymptotic-efficiency>#</a></h3><p>When we look at input size $n$ large enough that only the order of growth matters. We are concerned with the running time <em>in the limit</em> as input increases without bound.</p><h2 id=asymptotic-notation>Asymptotic Notation<a hidden class=anchor aria-hidden=true href=#asymptotic-notation>#</a></h2><p>Notation is defined as a function on domain $\mathbb{N} = { 0,1,2,\dots }$, the set of natural numbers. It is mainly used to characterise running time, but can also be used on memory/space/etc.</p><h3 id=theta-notation>$\Theta$-notation<a hidden class=anchor aria-hidden=true href=#theta-notation>#</a></h3><blockquote><p>Encloses the function from above and below</p></blockquote><p>Useful in analyzing the average-case complexity of an algorithm.
$$
\begin{aligned}
\Theta \big( g(n) \big)
= \{ f(n) :\ \text{there exists } c_1,\ c_2,\ n_0 \text{ such that } \\
0 \leq c_1 g(n) \leq f(n) \leq c_2 g(n) \enspace \forall n \geq n_0
\}
\end{aligned}
$$
$\Theta(n)$ is a set, but it is usually written as $f(n) = \Theta(n)$.</p><figure class=align-center><img loading=lazy src=theta-notation.JPG#center width=480></figure><p>$f(n)$ belongs to set $\Theta(g(n))$ if $c_1 \cdot g(n)$ and $c_2 \cdot g(n)$ can sandwidch the function, for large $n \geq n_0$.</p><p>The function $f(n)$ is equal to $g(n)$ to within a constant factor, which makes $g(n)$ an <strong>asymptotically tight bound</strong> for $f(n)$.</p><p>The definition of $\Theta(n)$ requires all $f(n) \in \Theta(g(n))$ be <strong>asymptotically nonnegative</strong> ($f(n) \geq 0$ as $n \rightarrow \infty$. This implies that $g(n)$ is also asymptotically nonnegative so that $\Theta(g(n))$ is not empty. Therefore assume that every function in $\Theta$-notation is asymptotically nonnegative.</p><blockquote><p><strong>Example</strong> Show that $ \frac{3}{4} n^2 - 5n + \frac{3}{n} = \Theta(n^2) $</p><p>$c_1 n^2 \leq \frac{3}{4} n^2 - 5n + \frac{3}{n} \leq c_2 n^2$ for all $n \geq n_0$</p><p>$c_1 \leq \frac{3}{4} - \frac{5}{n} + \frac{3}{n^2} \leq c_2$</p><p>$c_1 = \frac{1}{2}$, $c_2 = 1$ and $n_0 = 10$ satisfy the inequality</p></blockquote><blockquote><p><strong>Example</strong> Show that $5n^3 \neq \Theta(n^2)$</p><p>$c_1 \leq 5 \frac{n^3}{n^2} \leq c_2$</p><p>Which cannot hold for arbitrarily large $n$</p></blockquote><p>This results in two observations:</p><ul><li>The <strong>lower-order terms</strong> can be ignored
(They become of the form $1 / n^k$ which go to $0$)</li><li>Coefficients can be ignored
(Can be divided into $c_1, c_2$)</li></ul><p><strong>Constants</strong> are degree-0 polynomials, which can be expressed as $\Theta(n^0)$ or more commonly $\Theta(1)$.</p><h3 id=o-notation>$O$-notation<a hidden class=anchor aria-hidden=true href=#o-notation>#</a></h3><blockquote><p>Asymptotic upper bound</p></blockquote><p>Provides an upper bound on a function to within a constant factor.
$$
\begin{aligned}
O \big( g(n) \big)
= \{ f(n) :\ \text{there exists } c,\ n_0 \text{ such that } \\
0 \leq f(n) \leq c g(n) \enspace \forall n \geq n_0
\}
\end{aligned}
$$
$\Theta(g(n))$ implies $O(g(n))$ becauses $\Theta$-notation is stronger than $O$-notation.
$$
\Theta(g(n)) \subseteq O(g(n))
$$
$O$-notation provides an asymptotic upper bound but not a <strong>tight</strong> one. Distinguishing between both is stanard in algorithms literature, but not in informal use.</p><p>Inspection can often reveal the $O$-notation running time. For example, double nested loops are $O(n^2)$.</p><p>When $O$-notation is used to bound the worst-case running time, it also bounds <em>every input</em>. This is different from $\Theta$-notation, where the worse-case does not imply the running time for <em>every</em> input.</p><h3 id=omega-notation>$\Omega$-notation<a hidden class=anchor aria-hidden=true href=#omega-notation>#</a></h3><blockquote><p>Asymptotic lower bound</p></blockquote><p>$$
\begin{aligned}
O \big( g(n) \big)
= \{ f(n) :\ \text{there exists } c,\ n_0 \text{ such that } \\
0 \leq c g(n) \leq f(n) \enspace \forall n \geq n_0
\}
\end{aligned}
$$</p><h3 id=theorem-31>Theorem 3.1<a hidden class=anchor aria-hidden=true href=#theorem-31>#</a></h3><p>For any two functions $f(n)$ and $g(n)$, we have $f(n) = \Theta(g(n))$ if and only if $f(n) = O(g(n)) and f(n) = \Omega(g(n))$</p><p>Commonly used to get asymptotic upper/lower bounds ( $O$ / $\Omega$ ) from tight bounds ( $\Theta$ )</p><blockquote><p><strong>Example</strong></p><p>$ \Omega(n^2) = an^2 + bn + c$ and $O(n^2) = an^2 + bn + c$</p><p>imply that $ \Theta(n^2) = an^2 + bn + c $</p></blockquote></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://andrelimzs.github.io>AndreLimZS</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>