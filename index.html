<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AndreLimZS</title><meta name=description content><meta name=author content><link rel=canonical href=https://andrelimzs.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style><link rel=icon href=https://andrelimzs.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://andrelimzs.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://andrelimzs.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://andrelimzs.github.io/apple-touch-icon.png><link rel=mask-icon href=https://andrelimzs.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.96.0"><link rel=alternate type=application/rss+xml href=https://andrelimzs.github.io/index.xml><link rel=alternate type=application/json href=https://andrelimzs.github.io/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="AndreLimZS"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://andrelimzs.github.io/"><meta name=twitter:card content="summary"><meta name=twitter:title content="AndreLimZS"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"AndreLimZS","url":"https://andrelimzs.github.io","description":"","thumbnailUrl":"https://andrelimzs.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://andrelimzs.github.io accesskey=h title="AndreLimZS (Alt + H)">AndreLimZS</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>Andre Lim ZS</h1></header><section class=entry-content><p>Algorithm Engineer</p></section><footer class=entry-footer><div class=social-icons></div></footer></article><article class=post-entry><header class=entry-header><h2>CS229 Reinforcement Learning</h2></header><section class=entry-content><p>Reinforcement Learning Many sequential decision making and control problems are hard to provide explicit supervision for.
Instead provide a reward function and let the learning algorithm figure out how to choose actions over time.
Successful in applications such as helicopter flight, legged locomotion, network routing, marketing strategy selection, etc
Markov Decision Processes (MDP) Provide formalism for many RL problems
Terminology States : $s$ Actions : $a$ State Transition Probabilities : $P_{sa}$ Discount Factor : $\gamma \in [0,1)$ Reward Function : $R : S \times A \mapsto \mathbb{R}$ Dynamics of MDPs Start in some state $s_0$ Choose some action $a_0 \in A$ MDP randomly transitions to successor state $s_1 \sim P_{s_0a_0}$ Pick another action Repeat Represent as $$ s_0 \overset{a_0}{\rightarrow} s_1 \overset{a_1}{\rightarrow} s_2 \overset{a_2}{\rightarrow} s_3 \overset{a_3}{\rightarrow} \dots $$ Total Payoff $$ R(s_0, a_0) + \gamma R(s_1, a_1) + \gamma^2 R(s_2, a_2) + \dots $$ Goal : Maximise expected value of total payoff $$ E \left[ R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \dots \right] $$...</p></section><footer class=entry-footer><span title="2022-04-08 23:59:00 +0800 +0800">April 8, 2022</span></footer><a class=entry-link aria-label="post link to CS229 Reinforcement Learning" href=https://andrelimzs.github.io/posts/machine-learning/reinforcement-learning/></a></article><article class=post-entry><header class=entry-header><h2>CS229 Deep Learning</h2></header><section class=entry-content><p>Deep Learning Supervised with Nonlinear Models Supervised learning is
Predict $y$ from input $x$ Suppose model/hypothesis is $h_\theta(x)$ Previous methods have considered
Linear regression : $h_\theta(x) = \theta^Tx$ Kernel method : $h_\theta(x) = \theta^T \phi(x)$ Both are linear in $\theta$
Now consider models that are nonlinear in both
Parameters : $\theta$ Inputs : $x$ The most common of which is the neural network
Cost/Loss Function Define least-squares cost for one sample $$ J^{(i)}(\theta) = \frac{1}{2} ( h_\theta(x^{(i)}) - y^{(i)})^2 $$ and mean-square cost for the dataset $$ J(\theta) = \frac{1}{n} \sum_{i=1}^{n} J^{(i)}(\theta) $$...</p></section><footer class=entry-footer><span title="2022-04-08 22:00:00 +0800 +0800">April 8, 2022</span></footer><a class=entry-link aria-label="post link to CS229 Deep Learning" href=https://andrelimzs.github.io/posts/machine-learning/deep-learning/></a></article><article class=post-entry><header class=entry-header><h2>CS229 Generative Learning</h2></header><section class=entry-content><p>Generative Learning Different approach to learning
Try to model $p(x|y)$ and $p(y)$ instead of learning $p(y|x)$ directly
$p(x|y)$ : Distribution of the target’s features $p(y)$ : Class priors Use Bayes rule to calculate posterior distribution $p(y|x)$ $$ p(y|x) = \frac{p(x|y) p(y)}{p(x)} $$ Can be simplified when using for prediction because denominator doesn’t matter $$ \arg \max_y P(y|x) = \arg \max_y p(x|y) p(y) $$
Multivariate Normal Distribution In $d$-dimensions Parameterised by:...</p></section><footer class=entry-footer><span title="2022-04-07 22:00:00 +0800 +0800">April 7, 2022</span></footer><a class=entry-link aria-label="post link to CS229 Generative Learning" href=https://andrelimzs.github.io/posts/machine-learning/generative-learning/></a></article><article class=post-entry><header class=entry-header><h2>CS229 Supervised Learning</h2></header><section class=entry-content><p>Supervised Learning Terminology Input (Features) : $x^{(i)}$ Output (Target) : $y^{(i)}$ Training example : $(x^{(i)}, y^{(i)})$ Training set : Set of training examples Hypothesis : $h(x)$ Types Regression : Continuous values Classification : Discrete values (Linear) Regression First decide the hypothesis function
Where the convention is to let $x_0 = 1$ $$ h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 $$
$$ h(x) = \sum_{i=0}^d \theta_i x_i = \theta^T x $$...</p></section><footer class=entry-footer><span title="2022-04-06 22:00:00 +0800 +0800">April 6, 2022</span></footer><a class=entry-link aria-label="post link to CS229 Supervised Learning" href=https://andrelimzs.github.io/posts/machine-learning/supervised-learning/></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://andrelimzs.github.io>AndreLimZS</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>