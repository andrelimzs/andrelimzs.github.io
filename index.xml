<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>AndreLimZS</title><link>https://andrelimzs.github.io/</link><description>Recent content on AndreLimZS</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 07 Apr 2022 23:59:00 +0800</lastBuildDate><atom:link href="https://andrelimzs.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Reinforcement Learning</title><link>https://andrelimzs.github.io/posts/machine-learning/reinforcement-learning/</link><pubDate>Thu, 07 Apr 2022 23:59:00 +0800</pubDate><guid>https://andrelimzs.github.io/posts/machine-learning/reinforcement-learning/</guid><description>Reinforcement Learning Many sequential decision making and control problems are hard to provide explicit supervision for.
Instead provide a reward function and let the learning algorithm figure out how to choose actions over time.
Successful in applications such as helicopter flight, legged locomotion, network routing, marketing strategy selection, etc
Markov Decision Processes (MDP) Provide formalism for many RL problems
Terminology States : $s$ Actions : $a$ State Transition Probabilities : $P_{sa}$ Discount Factor : $\gamma \in [0,1)$ Reward Function : $R : S \times A \mapsto \mathbb{R}$ Dynamics of MDPs Start in some state $s_0$ Choose some action $a_0 \in A$ MDP randomly transitions to successor state $s_1 \sim P_{s_0a_0}$ Pick another action Repeat Represent as $$ s_0 \overset{a_0}{\rightarrow} s_1 \overset{a_1}{\rightarrow} s_2 \overset{a_2}{\rightarrow} s_3 \overset{a_3}{\rightarrow} \dots $$ Total Payoff $$ R(s_0, a_0) + \gamma R(s_1, a_1) + \gamma^2 R(s_2, a_2) + \dots $$ Goal : Maximise expected value of total payoff $$ E \left[ R(s_0) + \gamma R(s_1) + \gamma^2 R(s_2) + \dots \right] $$</description></item><item><title/><link>https://andrelimzs.github.io/posts/convex-optimisation/convex-optimisation-problems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://andrelimzs.github.io/posts/convex-optimisation/convex-optimisation-problems/</guid><description>Standard Form</description></item></channel></rss>